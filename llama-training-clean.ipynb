{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e013210b",
   "metadata": {},
   "source": [
    "# Training llama models from scratch\n",
    "\n",
    "Import all needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3615b-35a8-4429-9b62-6bfa77e7677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm \n",
    "\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer)\n",
    "\n",
    "from tokenizers.normalizers import Lowercase, Strip, StripAccents, NFD\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    PreTrainedTokenizerFast, \n",
    "    set_seed, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    DataCollatorForLanguageModeling, \n",
    "    LlamaForCausalLM, \n",
    "    LlamaConfig)\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a828c42b-e9f3-4da6-a0e8-cd77dfc1b316",
   "metadata": {},
   "source": [
    "### Paths\n",
    "\n",
    "Set paths to training data, eval data, and model directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e701f0-1f65-4065-8457-7b82a59a4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = ['/path/to/training/file1',\n",
    "                 '/path/to/training/file2',\n",
    "                 '/path/to/training/file3',\n",
    "                 '/path/to/training/etc',]\n",
    "\n",
    "eval_files = ['/path/to/eval/file1',\n",
    "             '/path/to/eval/file2',\n",
    "             '/path/to/eval/file3',\n",
    "             '/path/to/eval/etc',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc6a5c-caed-4894-b44f-93aa8cf873c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/path/to/model/dir'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4e385",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb4723",
   "metadata": {},
   "source": [
    "Initialize with BPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1208c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.BPE())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e4b9a",
   "metadata": {},
   "source": [
    "Normalizer that sets everything to normal unicode, lowercase, and strips white spaces and accents\n",
    "\n",
    "(explanations here: https://huggingface.co/docs/tokenizers/components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = normalizers.Sequence([NFD(), Lowercase(), Strip(), StripAccents()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer.normalize_str(\"Héllò hôw are ü?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.normalizer = normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a2ea64",
   "metadata": {},
   "source": [
    "Pre-tokenization (division of text into tokens on which BPE can be performed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff60ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test pre-tokenization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7334f243-68c2-4ffb-9035-8dd44a6b2df1",
   "metadata": {},
   "source": [
    "Set vocab size, add special tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainers.BpeTrainer(vocab_size=16000, #special_tokens=[\"<|endoftext|>\", \"<pad>\",]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(files = training_files, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e94458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b82e68",
   "metadata": {},
   "source": [
    "By default, the ByteLevel BPE might include whitespaces in the produced tokens. If you don’t want the offsets to include these whitespaces, then this PostProcessor must be used:\n",
    "\n",
    "(https://huggingface.co/docs/tokenizers/api/post-processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f57718",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.ByteLevel(trim_offsets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3146c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Let's test this tokenizer.\"\n",
    "encoding = tokenizer.encode(sentence)\n",
    "start, end = encoding.offsets[4]\n",
    "sentence[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c4f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.ByteLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3401dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(encoding.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456297ab",
   "metadata": {},
   "source": [
    "Save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    bos_token=\"<|endoftext|>\",\n",
    "    eos_token=\"<|endoftext|>\",\n",
    "    pad_token=\"<pad>\",\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_tokenizer.save_pretrained(model_path+'tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf5ef16",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727dff5b",
   "metadata": {},
   "source": [
    "Load tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c13c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path+'tokenizer/')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee9ff6-57d5-47d2-b03a-7fde61390414",
   "metadata": {},
   "source": [
    "Load data (now for training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cf1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset('text', data_files={'train': training_files, \n",
    "                                           'validation': eval_files})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daebd899",
   "metadata": {},
   "source": [
    "Creates batches (https://huggingface.co/docs/transformers/pad_truncation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39eace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True)\n",
    "    \n",
    "    input_batch = []\n",
    "    \n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize, \n",
    "                                      batched=True, \n",
    "                                      remove_columns=raw_datasets[\"train\"].column_names)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb7482",
   "metadata": {},
   "source": [
    "Initiate new Llama with config as wished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d589d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LlamaConfig(\n",
    "    vocab_size=269,\n",
    "    hidden_size=512,\n",
    "    num_hidden_layers=8,\n",
    "    intermediate_size=512,\n",
    "    num_attention_heads=8,\n",
    "    bos_token_id=tokenizer.convert_tokens_to_ids(\"<|endoftext|>\"),\n",
    "    eos_token_id=tokenizer.convert_tokens_to_ids(\"<|endoftext|>\"),\n",
    "    pad_token_id=tokenizer.convert_tokens_to_ids(\"<pad>\"),\n",
    "    max_position_embeddings=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de1e5e3-bea9-4ca2-bbe6-7b414e379fe8",
   "metadata": {},
   "source": [
    "Set seed for weight initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c99f330-8a8c-4878-ac9c-9e576e488be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a9ab15-5773-4a81-ba4a-308f389093a1",
   "metadata": {},
   "source": [
    "New model object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LlamaForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6343c2e-30bc-4e99-ab8d-9a2d3d4c37ae",
   "metadata": {},
   "source": [
    "Check out param size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f276d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model num parameters = {model.num_parameters()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = config.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b112127-7368-4fc6-a6a5-e990bbbe625c",
   "metadata": {},
   "source": [
    "Set training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bee44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    overwrite_output_dir=True,\n",
    "    save_strategy = \"epoch\", # saves after every epoch\n",
    "    #save_strategy = \"steps\", \n",
    "    #save_steps = 0.1, # if below zero, then saves after every (n*100)% of training steps\n",
    "    #save_total_limit=100,  # set to zero to avoid saving\n",
    "    eval_strategy = \"epoch\",\n",
    "    #eval_steps = 0.1,\n",
    "    num_train_epochs= 5,\n",
    "    #max_steps = 1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    per_device_train_batch_size=16,\n",
    "    warmup_steps=200, \n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=3e-4, # normal: 5e-4\n",
    "    logging_steps=10,\n",
    "    #fp16=True, ## only on CUDA\n",
    "    #load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    #use_mps_device=True, ## only on apple silicon\n",
    "    #use_cpu = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3537432-881c-42ed-83d4-fef5456efe45",
   "metadata": {},
   "source": [
    "Initialize trainer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets['train'],#[:15000]['input_ids'],\n",
    "    eval_dataset=tokenized_datasets['validation']#[:1200]['input_ids'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d20de00-46b5-478c-a92a-58f0e5433bd8",
   "metadata": {},
   "source": [
    "Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca36080",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f7370f-bb06-44a8-b873-5519f5c31cb4",
   "metadata": {},
   "source": [
    "Save logs of losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00de27-3260-49fd-8865-6980e8bbe5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(trainer.state.log_history)\n",
    "df.to_csv(model_path+'logs/losses.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a05f8-34d0-402b-a785-0a729d6ebea0",
   "metadata": {},
   "source": [
    "Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68875c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_path+'final/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debbe5e-1a7b-49bf-bde3-cd6c23e06608",
   "metadata": {},
   "source": [
    "### Test trained model on text generation\n",
    "\n",
    "With hf pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a24ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"/home/bastian/Dokumente/llamaphone/grapheme-whitespace/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77720de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"I am the\", do_sample = True, \n",
    "     num_return_sequences = 20, \n",
    "     max_length=128\n",
    "     #top_k=50,\n",
    "     #top_p=0.8,\n",
    "     #temperature=1.0,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
